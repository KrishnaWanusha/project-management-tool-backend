{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xTLVlA9pffgc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTLVlA9pffgc",
    "outputId": "012f089f-f63b-4ba2-a4c7-070c7825b71d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x5pdcb2djb9C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5pdcb2djb9C",
    "outputId": "126ee1b4-531d-416f-ff06-03d8758da2ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mabwiser in /usr/local/lib/python3.10/dist-packages (2.7.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from mabwiser) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from mabwiser) (1.26.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mabwiser) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from mabwiser) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mabwiser) (1.13.1)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from mabwiser) (0.13.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->mabwiser) (3.5.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn>=0.9.0->mabwiser) (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->mabwiser) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mabwiser) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->mabwiser) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.9.0->mabwiser) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.9.0->mabwiser) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.9.0->mabwiser) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.9.0->mabwiser) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.9.0->mabwiser) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.9.0->mabwiser) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.9.0->mabwiser) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->mabwiser) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mabwiser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uymW6OZnmahU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uymW6OZnmahU",
    "outputId": "9f8b82be-67f0-43db-9629-0eadef241f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Storypoint Distribution:\n",
      "storypoint\n",
      " 1     818\n",
      " 3     755\n",
      " 2     643\n",
      " 5     565\n",
      " 8     397\n",
      " 4     211\n",
      "-1      66\n",
      " 10     44\n",
      " 6      27\n",
      "Name: count, dtype: int64\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None, 'bootstrap': True}\n",
      "Initial Accuracy: 32.72%\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"/content/drive/MyDrive/RiskAssessment/spring.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Preprocess the dataset\n",
    "# Fill missing values in 'description' with empty strings\n",
    "data['description'] = data['description'].fillna(\"\")\n",
    "\n",
    "# Combine 'title' and 'description' into a new column 'text'\n",
    "data['text'] = data['title'] + \" \" + data['description']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['issuekey', 'title', 'description'])\n",
    "\n",
    "# Handle rare classes in 'storypoint'\n",
    "# Group rare story points into a single category labeled -1\n",
    "storypoint_counts = data['storypoint'].value_counts()\n",
    "rare_classes = storypoint_counts[storypoint_counts < 20].index\n",
    "data['storypoint'] = data['storypoint'].apply(lambda x: -1 if x in rare_classes else x)\n",
    "\n",
    "# Check the distribution of the updated 'storypoint'\n",
    "print(\"Updated Storypoint Distribution:\")\n",
    "print(data['storypoint'].value_counts())\n",
    "\n",
    "# Feature transformation using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')\n",
    "X = tfidf.fit_transform(data['text'])\n",
    "\n",
    "# Target variable\n",
    "y = data['storypoint']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Define parameter grid for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_clf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Perform 20 random searches\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract the best hyperparameters and the best model\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred_initial = best_model.predict(X_test)\n",
    "\n",
    "# Calculate initial accuracy\n",
    "initial_accuracy = accuracy_score(y_test, y_pred_initial)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(f\"Initial Accuracy: {initial_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0a5f3-14c2-4a20-95af-2dae7aafe308",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7db0a5f3-14c2-4a20-95af-2dae7aafe308",
    "outputId": "c3001a82-43b7-442c-920e-3b05d2115359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Prediction Accuracy: 33.00%\n",
      "Refined Prediction Accuracy: 14.16%\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mabwiser.mab import LearningPolicy, MAB\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"/content/drive/MyDrive/RiskAssessment/spring.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Fill missing values in 'description' by reassigning to the column instead of using inplace=True\n",
    "data['description'] = data['description'].fillna(\"\")\n",
    "\n",
    "# Set 'storypoint' as the target variable\n",
    "X = data.drop(columns=['storypoint'])\n",
    "y = data['storypoint']\n",
    "\n",
    "# Text Preprocessing using TF-IDF for 'title' and 'description' columns\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('tfidf_title', TfidfVectorizer(), 'title'),\n",
    "    ('tfidf_description', TfidfVectorizer(), 'description')\n",
    "], remainder='drop')\n",
    "\n",
    "X_transformed = column_transformer.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Initial Predictions\n",
    "initial_predictions = clf.predict(X_test)\n",
    "\n",
    "# Evaluate initial model accuracy\n",
    "initial_accuracy = accuracy_score(y_test, initial_predictions)\n",
    "print(f\"Initial Prediction Accuracy: {initial_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Define possible actions (adjustments to story points)\n",
    "actions = [-1, 0, 1]\n",
    "\n",
    "# Convert actual outcomes to a numpy array for compatibility\n",
    "actual_outcomes = y_test.to_numpy()\n",
    "\n",
    "# Calculate rewards based on how close the initial prediction is to the actual outcome\n",
    "# Reward of 1 if within 1 point of the actual outcome, otherwise -1\n",
    "rewards = [1 if abs(pred - actual) <= 1 else -1 for pred, actual in zip(initial_predictions, actual_outcomes)]\n",
    "\n",
    "# Set up Multi-Armed Bandit model with epsilon-greedy policy\n",
    "mab = MAB(arms=actions, learning_policy=LearningPolicy.EpsilonGreedy(epsilon=0.1))\n",
    "\n",
    "# Fit the MAB model on the initial predictions and rewards\n",
    "mab.fit(decisions=initial_predictions, rewards=rewards)\n",
    "\n",
    "# Refine predictions using MAB - make adjustments based on the bandit's recommendations\n",
    "refined_predictions = []\n",
    "for pred in initial_predictions:\n",
    "    # Get the adjustment recommendation from the MAB model (pass a 2D array as context)\n",
    "    adjustment = mab.predict([[pred]])  \n",
    "    # Apply the adjustment to the initial prediction\n",
    "    refined_predictions.append(pred + adjustment)\n",
    "\n",
    "# Convert refined predictions to numpy array for accuracy calculation\n",
    "refined_predictions = np.array(refined_predictions)\n",
    "\n",
    "# Evaluate the refined predictions\n",
    "refined_accuracy = accuracy_score(actual_outcomes, refined_predictions)\n",
    "print(f\"Refined Prediction Accuracy: {refined_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M_uDAclAo6Mo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_uDAclAo6Mo",
    "outputId": "07d0bab3-7f71-4539-a045-6d34bd317996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [14:28:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [14:31:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 75.02%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.99      0.98       164\n",
      "           1       0.44      0.60      0.51       163\n",
      "           2       0.59      0.52      0.55       164\n",
      "           3       0.47      0.32      0.38       164\n",
      "           4       0.89      0.91      0.90       164\n",
      "           5       0.71      0.55      0.62       163\n",
      "           6       0.99      1.00      0.99       164\n",
      "           8       0.69      0.86      0.77       163\n",
      "          10       1.00      0.99      0.99       164\n",
      "\n",
      "    accuracy                           0.75      1473\n",
      "   macro avg       0.75      0.75      0.74      1473\n",
      "weighted avg       0.75      0.75      0.74      1473\n",
      "\n",
      "XGBoost Accuracy: 70.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.95      0.97       164\n",
      "           1       0.39      0.45      0.42       163\n",
      "           2       0.52      0.48      0.50       164\n",
      "           3       0.32      0.35      0.34       164\n",
      "           4       0.90      0.85      0.87       164\n",
      "           5       0.57      0.55      0.56       163\n",
      "           6       1.00      0.98      0.99       164\n",
      "           8       0.74      0.77      0.76       163\n",
      "          10       1.00      0.97      0.98       164\n",
      "\n",
      "    accuracy                           0.70      1473\n",
      "   macro avg       0.71      0.70      0.71      1473\n",
      "weighted avg       0.71      0.70      0.71      1473\n",
      "\n",
      "Ensemble Accuracy: 73.18%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.97      0.98       164\n",
      "           1       0.43      0.52      0.47       163\n",
      "           2       0.55      0.51      0.53       164\n",
      "           3       0.35      0.32      0.34       164\n",
      "           4       0.91      0.87      0.89       164\n",
      "           5       0.65      0.60      0.63       163\n",
      "           6       1.00      0.99      0.99       164\n",
      "           8       0.73      0.82      0.77       163\n",
      "          10       1.00      0.99      0.99       164\n",
      "\n",
      "    accuracy                           0.73      1473\n",
      "   macro avg       0.73      0.73      0.73      1473\n",
      "weighted avg       0.73      0.73      0.73      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"/content/drive/MyDrive/RiskAssessment/spring.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Preprocess the dataset\n",
    "data['description'] = data['description'].fillna(\"\")\n",
    "data['text'] = data['title'] + \" \" + data['description']\n",
    "data = data.drop(columns=['issuekey', 'title', 'description'])\n",
    "\n",
    "# Handle rare classes in 'storypoint'\n",
    "storypoint_counts = data['storypoint'].value_counts()\n",
    "rare_classes = storypoint_counts[storypoint_counts < 20].index\n",
    "data['storypoint'] = data['storypoint'].apply(lambda x: -1 if x in rare_classes else x)\n",
    "\n",
    "# Map storypoint labels to consecutive integers\n",
    "unique_storypoints = sorted(data['storypoint'].unique())\n",
    "label_mapping = {label: idx for idx, label in enumerate(unique_storypoints)}\n",
    "inverse_mapping = {idx: label for label, idx in label_mapping.items()}\n",
    "data['storypoint'] = data['storypoint'].map(label_mapping)\n",
    "\n",
    "# Feature transformation using TF-IDF with trigrams and increased features\n",
    "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 3), stop_words='english')\n",
    "X = tfidf.fit_transform(data['text'])\n",
    "\n",
    "# Target variable\n",
    "y = data['storypoint']\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_param_distributions = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=rf_clf,\n",
    "    param_distributions=rf_param_distributions,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "best_rf_model = random_search_rf.best_estimator_\n",
    "\n",
    "# Train XGBoost Classifier\n",
    "xgb_clf = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Ensemble Model: Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', best_rf_model),\n",
    "    ('xgb', xgb_clf)\n",
    "], voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Models\n",
    "models = {\n",
    "    'Random Forest': best_rf_model,\n",
    "    'XGBoost': xgb_clf,\n",
    "    'Ensemble': voting_clf\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_original = [inverse_mapping[pred] for pred in y_pred]  \n",
    "    y_test_original = [inverse_mapping[true] for true in y_test]  \n",
    "    accuracy = accuracy_score(y_test_original, y_pred_original)\n",
    "    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(classification_report(y_test_original, y_pred_original))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec455bea-25a0-4b26-b243-7e4300bffa76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "ec455bea-25a0-4b26-b243-7e4300bffa76",
    "outputId": "4dccf496-56f9-4efa-f8db-7c2865c0dce9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8c65e5bc5a71>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Collect accuracy scores for each model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0my_pred_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minverse_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Dictionary to store accuracy scores\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Collect accuracy scores for each model\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_original = [inverse_mapping[pred] for pred in y_pred]\n",
    "    y_test_original = [inverse_mapping[true] for true in y_test]\n",
    "    accuracy = accuracy_score(y_test_original, y_pred_original)\n",
    "    accuracy_scores[model_name] = accuracy * 100  # Store percentage value\n",
    "\n",
    "# Visualization: Accuracy Scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=list(accuracy_scores.keys()), y=list(accuracy_scores.values()), palette=\"viridis\")\n",
    "plt.title(\"Accuracy Scores of Models\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_model_name = max(accuracy_scores, key=accuracy_scores.get) \n",
    "best_model = models[best_model_name]\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_pred_original_best = [inverse_mapping[pred] for pred in y_pred_best]\n",
    "y_test_original_best = [inverse_mapping[true] for true in y_test]\n",
    "\n",
    "# Confusion Matrix Display\n",
    "plt.figure(figsize=(10, 8))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test_original_best,\n",
    "    y_pred_original_best,\n",
    "    display_labels=sorted(data['storypoint'].unique()),\n",
    "    cmap=\"Blues\",\n",
    "    xticks_rotation=45\n",
    ")\n",
    "plt.title(f\"Confusion Matrix: {best_model_name}\")\n",
    "plt.show()\n",
    "\n",
    "# Classification Report Metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Collect metrics\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_test_original_best, y_pred_original_best, average=None, zero_division=0\n",
    ")\n",
    "labels = sorted(data['storypoint'].unique())\n",
    "\n",
    "# Plot Precision, Recall, and F1-score\n",
    "metrics = pd.DataFrame({\n",
    "    \"Label\": labels,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1-score\": f1\n",
    "})\n",
    "\n",
    "metrics_melted = metrics.melt(id_vars=\"Label\", var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=metrics_melted, x=\"Label\", y=\"Score\", hue=\"Metric\", palette=\"coolwarm\")\n",
    "plt.title(f\"Metrics by Label for {best_model_name}\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8f543-b437-47f6-aefa-3395538e41d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2df8f543-b437-47f6-aefa-3395538e41d4",
    "outputId": "69654d2e-9c25-4ec0-f93f-8affcf119ab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Prediction Accuracy (Random Forest): 75.90%\n",
      "Refined Prediction Accuracy (Hybrid Model): 71.15%\n",
      "\n",
      "Classification Report for Hybrid Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.95      0.95       164\n",
      "           1       0.42      0.53      0.47       163\n",
      "           2       0.51      0.54      0.53       164\n",
      "           3       0.45      0.31      0.37       164\n",
      "           4       0.85      0.87      0.86       164\n",
      "           5       0.65      0.52      0.58       163\n",
      "           6       0.92      0.98      0.95       164\n",
      "           8       0.69      0.78      0.73       163\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.97      0.93      0.95       164\n",
      "\n",
      "    accuracy                           0.71      1473\n",
      "   macro avg       0.64      0.64      0.64      1473\n",
      "weighted avg       0.71      0.71      0.71      1473\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from mabwiser.mab import LearningPolicy, NeighborhoodPolicy, MAB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"/content/drive/MyDrive/RiskAssessment/spring.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Preprocess the dataset\n",
    "data['description'] = data['description'].fillna(\"\")\n",
    "data['text'] = data['title'] + \" \" + data['description']\n",
    "data = data.drop(columns=['issuekey', 'title', 'description'])\n",
    "\n",
    "# Handle rare classes in 'storypoint'\n",
    "storypoint_counts = data['storypoint'].value_counts()\n",
    "rare_classes = storypoint_counts[storypoint_counts < 20].index\n",
    "data['storypoint'] = data['storypoint'].apply(lambda x: -1 if x in rare_classes else x)\n",
    "\n",
    "# Feature transformation using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')\n",
    "X = tfidf.fit_transform(data['text'])\n",
    "\n",
    "# Map storypoint labels to consecutive integers\n",
    "unique_storypoints = sorted(data['storypoint'].unique())\n",
    "label_mapping = {label: idx for idx, label in enumerate(unique_storypoints)}\n",
    "inverse_mapping = {idx: label for label, idx in label_mapping.items()}\n",
    "data['storypoint'] = data['storypoint'].map(label_mapping)\n",
    "\n",
    "# Target variable\n",
    "y = data['storypoint']\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# Train a supervised model (Random Forest Classifier)\n",
    "rf_clf = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=200)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make initial predictions using the supervised model\n",
    "initial_predictions = rf_clf.predict(X_test)\n",
    "\n",
    "# Map predictions back to original storypoint labels\n",
    "initial_predictions_original = [inverse_mapping[pred] for pred in initial_predictions]\n",
    "y_test_original = [inverse_mapping[true] for true in y_test]\n",
    "\n",
    "# Evaluate initial predictions\n",
    "initial_accuracy = accuracy_score(y_test_original, initial_predictions_original)\n",
    "print(f\"Initial Prediction Accuracy (Random Forest): {initial_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Define MAB actions (adjustments to storypoints)\n",
    "actions = [-1, 0, 1]\n",
    "\n",
    "# Calculate rewards for initial predictions\n",
    "rewards = [\n",
    "    1 if abs(pred - true) <= 1 else -1\n",
    "    for pred, true in zip(initial_predictions_original, y_test_original)\n",
    "]\n",
    "\n",
    "# Set up MAB with epsilon-greedy policy\n",
    "mab = MAB(\n",
    "    arms=actions,\n",
    "    learning_policy=LearningPolicy.EpsilonGreedy(epsilon=0.1)\n",
    ")\n",
    "\n",
    "# Train MAB on initial predictions and rewards\n",
    "mab.fit(decisions=initial_predictions, rewards=rewards)\n",
    "\n",
    "# Refine predictions using MAB\n",
    "refined_predictions = []\n",
    "for pred in initial_predictions:\n",
    "    # Get adjustment recommendation from MAB\n",
    "    # adjustment = mab.predict([[pred]])[0]\n",
    "    adjustment = mab.predict([[pred]])\n",
    "\n",
    "    refined_predictions.append(pred + adjustment)\n",
    "\n",
    "# Map refined predictions back to original storypoint labels\n",
    "refined_predictions_original = [inverse_mapping.get(pred, pred) for pred in refined_predictions]\n",
    "\n",
    "# Evaluate refined predictions\n",
    "refined_accuracy = accuracy_score(y_test_original, refined_predictions_original)\n",
    "print(f\"Refined Prediction Accuracy (Hybrid Model): {refined_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report for Hybrid Model:\")\n",
    "print(classification_report(y_test_original, refined_predictions_original))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kCAjAS1iXUST",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCAjAS1iXUST",
    "outputId": "6d9d458c-f504-45ab-c9ea-a07b33072f49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Storypoint for 'Design for deploying XD on EC2' - 'Create enough of a design to develop additional stories.': 5\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inverse_mapping = {\n",
    "    0: 1,\n",
    "    1: 3,\n",
    "    2: 2,\n",
    "    3: 5,\n",
    "    4: 8,\n",
    "    5: 4,\n",
    "    6: -1,\n",
    "    7: 10,\n",
    "    8: 6\n",
    "}\n",
    "\n",
    "# Define the function to predict storypoints\n",
    "def predict_storypoint(title, description):\n",
    "    \"\"\"\n",
    "    Predict the storypoint for a given task using the pre-trained Random Forest model.\n",
    "\n",
    "    :param title: Title of the task\n",
    "    :param description: Description of the task\n",
    "    :return: Adjusted predicted storypoint\n",
    "    \"\"\"\n",
    "    # Combine title and description into a single text field\n",
    "    text = title + \" \" + description\n",
    "\n",
    "    # Transform the input text using TF-IDF vectorizer\n",
    "    input_tfidf = tfidf.transform([text])\n",
    "\n",
    "    # Predict the initial storypoint using the Random Forest model\n",
    "    initial_prediction = rf_clf.predict(input_tfidf)[0]\n",
    "\n",
    "    # Map the initial prediction back to the original storypoint using the inverse mapping\n",
    "    predicted_storypoint = inverse_mapping.get(initial_prediction, initial_prediction)\n",
    "\n",
    "    return predicted_storypoint\n",
    "\n",
    "\n",
    "title_input = \"Design for deploying XD on EC2\"\n",
    "description_input = \"Create enough of a design to develop additional stories.\"\n",
    "\n",
    "\n",
    "predicted_storypoint = predict_storypoint(title_input, description_input)\n",
    "\n",
    "# Output the result\n",
    "print(f\"Predicted Storypoint for '{title_input}' - '{description_input}': {predicted_storypoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GDAMbCEB8lJa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GDAMbCEB8lJa",
    "outputId": "56ca8ba8-4acf-41b1-aae9-3921fb2e6a0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Storypoint for 'Design for deploying XD on EC2' - 'Create enough of a design to develop additional stories.': 5\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from mabwiser.mab import LearningPolicy, MAB\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "inverse_mapping = {\n",
    "    0: 1,\n",
    "    1: 3,\n",
    "    2: 2,\n",
    "    3: 5,\n",
    "    4: 8,\n",
    "    5: 4,\n",
    "    6: -1,\n",
    "    7: 10,\n",
    "    8: 6\n",
    "}\n",
    "\n",
    "# Define the function to predict story points using refined prediction\n",
    "def predict_storypoint_refined(title, description):\n",
    "    \"\"\"\n",
    "    Predict the story point for a given task using a combination of a Random Forest classifier\n",
    "    and Multi-Armed Bandit (MAB) adjustments.\n",
    "\n",
    "    :param title: Title of the task\n",
    "    :param description: Description of the task\n",
    "    :return: Refined predicted story point\n",
    "    \"\"\"\n",
    "    # Combine title and description into a single text field\n",
    "    text = title + \" \" + description\n",
    "\n",
    "    # Transform the input text using the TF-IDF vectorizer\n",
    "    input_tfidf = tfidf.transform([text])\n",
    "\n",
    "    # Predict the initial story point using the Random Forest model\n",
    "    initial_prediction = rf_clf.predict(input_tfidf)[0]\n",
    "\n",
    "    # Get the MAB adjustment for the initial prediction\n",
    "    adjustment = mab.predict([[initial_prediction]])\n",
    "\n",
    "    # Apply the adjustment to refine the prediction\n",
    "    refined_prediction = initial_prediction + adjustment\n",
    "\n",
    "    # Map the refined prediction back to the original story point using the inverse mapping\n",
    "    predicted_storypoint = inverse_mapping.get(refined_prediction, refined_prediction)\n",
    "\n",
    "    return predicted_storypoint\n",
    "\n",
    "\n",
    "# Example Inputs\n",
    "title_input = \"Design for deploying XD on EC2\"\n",
    "description_input = \"Create enough of a design to develop additional stories.\"\n",
    "\n",
    "# Predict refined story point\n",
    "predicted_storypoint = predict_storypoint_refined(title_input, description_input)\n",
    "\n",
    "# Output the result\n",
    "print(f\"Predicted Storypoint for '{title_input}' - '{description_input}': {predicted_storypoint}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
